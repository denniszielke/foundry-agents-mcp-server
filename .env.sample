# ── Azure AI Foundry ──────────────────────────────────────────────────────────
# Endpoint of your Azure AI Foundry project
# Format: https://<hub>.services.ai.azure.com/api/projects/<project>
AZURE_AI_PROJECT_ENDPOINT=https://<hub>.services.ai.azure.com/api/projects/<project>

# ── Azure AI Search ───────────────────────────────────────────────────────────
AZURE_AI_SEARCH_ENDPOINT=https://<search-service>.search.windows.net
AZURE_AI_SEARCH_INDEX_NAME=project-log-index

# ── Azure OpenAI ──────────────────────────────────────────────────────────────
# Leave blank to use AZURE_AI_PROJECT_ENDPOINT for model inference
AZURE_OPENAI_ENDPOINT=

# Embedding model deployment name
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-3-small
AZURE_OPENAI_EMBEDDING_DIMENSIONS=1536

# Chat/completion model deployment name
AZURE_OPENAI_COMPLETION_MODEL_NAME=gpt-4o

# ── Application Insights (optional) ──────────────────────────────────────────
# Filled automatically by `azd provision` / infra/write_env.sh
APPLICATIONINSIGHTS_CONNECTION_STRING=

# ── Container runtime (do not change for local stdio usage) ──────────────────
# TRANSPORT=http   → uvicorn HTTP server (Container Apps)
# TRANSPORT=stdio  → stdio MCP server   (local / uvx)
TRANSPORT=stdio

# ── Production flag (set automatically by Dockerfile / Container Apps) ────────
# When true, uses ManagedIdentityCredential(client_id=AZURE_CLIENT_ID)
RUNNING_IN_PRODUCTION=false
AZURE_CLIENT_ID=
