# ── Azure AI Foundry ──────────────────────────────────────────────────────────
# AI Foundry project endpoint – used by AIProjectClient (agents API)
# Format: https://<account>.services.ai.azure.com/api/projects/<project>
AZURE_AI_PROJECT_ENDPOINT=https://<account>.services.ai.azure.com/api/projects/<project>

# OpenAI-compatible endpoint – used by AzureOpenAI client (embeddings, completions)
# For AIServices accounts this is typically https://<account>.openai.azure.com/
# If left blank, AZURE_AI_PROJECT_ENDPOINT is used as a fallback.
AZURE_OPENAI_ENDPOINT=

# Completion model deployment name (must be deployed in the Foundry account)
AZURE_OPENAI_COMPLETION_MODEL_NAME=gpt-4o

# Embedding model deployment name and vector dimensions
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-3-small
AZURE_OPENAI_EMBEDDING_DIMENSIONS=1536

# ── Azure AI Search ───────────────────────────────────────────────────────────
AZURE_AI_SEARCH_ENDPOINT=https://<search-service>.search.windows.net
AZURE_AI_SEARCH_INDEX_NAME=project-log-index

# ── Application Insights (filled by infra/write_env.sh after azd provision) ──
APPLICATIONINSIGHTS_CONNECTION_STRING=

# ── Local transport ───────────────────────────────────────────────────────────
# stdio → uvx / VS Code MCP client
# http  → uvicorn HTTP server (test the container locally)
TRANSPORT=stdio

# ── Production flags (set automatically by Container Apps) ───────────────────
RUNNING_IN_PRODUCTION=false
AZURE_CLIENT_ID=
